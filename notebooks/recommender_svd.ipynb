{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx6KbAhhMcM0+5iEDuNgEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovrodukic/music-recommendation/blob/main/notebooks/recommender_svd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Preprocess Last.fm dataset to prepare it for building a recommendation system."
      ],
      "metadata": {
        "id": "72MbT4vH1UxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /content/datasets https://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip\n",
        "!unzip /content/datasets/hetrec2011-lastfm-2k.zip -d /content/datasets\n",
        "!ls /content/datasets\n",
        "# Install required libraries\n",
        "!pip install pandas numpy scikit-learn surprise matplotlib"
      ],
      "metadata": {
        "id": "84KC3Xl8hkS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KmqHe-KpX9KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_user_artists(user_artists_file):\n",
        "    \"\"\"\n",
        "    Load the user-artists interactions data\n",
        "    \"\"\"\n",
        "    return pd.read_csv(user_artists_file, sep='\\t')\n",
        "\n",
        "def load_artists(artists_file):\n",
        "    \"\"\"\n",
        "    Load the artists data\n",
        "    \"\"\"\n",
        "    return pd.read_csv(artists_file, sep='\\t')\n",
        "\n",
        "user_artists = load_user_artists('/content/datasets/user_artists.dat')\n",
        "print(\"User-Artists Interactions:\")\n",
        "print(user_artists.head())\n",
        "\n",
        "# Load the artist data\n",
        "artists = load_artists('/content/datasets/artists.dat')\n",
        "print(\"Artists Data:\")\n",
        "print(artists.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HsWG3O1l1n3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick info about the datasets\n",
        "user_artists.info()\n",
        "artists.info()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in user_artists:\\n\", user_artists.isnull().sum())\n",
        "print(\"\\nMissing values in artists:\\n\", artists.isnull().sum())\n",
        "\n",
        "# Remove duplicates in user_artists\n",
        "initial_count = len(user_artists)\n",
        "user_artists.drop_duplicates(inplace=True)\n",
        "print(f\"\\nRemoved {initial_count - len(user_artists)} duplicates.\")\n",
        "\n",
        "# Normalize weights to a 0-1 scale\n",
        "# user_artists['weight'] = (user_artists['weight'] - user_artists['weight'].min()) / (user_artists['weight'].max() - user_artists['weight'].min())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "m8BmTcUK3Tac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_weights(user_artists):\n",
        "    user_artists['log_weight'] = np.log1p(user_artists['weight'])  # Use log1p to handle zero weights\n",
        "    min_log_weight = user_artists['log_weight'].min()\n",
        "    max_log_weight = user_artists['log_weight'].max()\n",
        "\n",
        "    # Normalize the log-transformed weights to the range [1, 5]\n",
        "    user_artists['normalized_weight'] = 1 + 4 * (user_artists['log_weight'] - min_log_weight) / (max_log_weight - min_log_weight)\n",
        "\n",
        "    return user_artists\n",
        "\n",
        "user_artists = normalize_weights(user_artists)\n",
        "\n",
        "# Check the range after normalization\n",
        "print(\"Log-transformed and normalized weight range:\", user_artists['normalized_weight'].min(), \"-\", user_artists['normalized_weight'].max())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c7VZWt4RJnWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training\n",
        "\n",
        "Training a collaborative filtering model using Singular Value Decomposition (SVD)"
      ],
      "metadata": {
        "id": "RCjdHgQL7kbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "def transform_data(user_artists):\n",
        "    \"\"\"\n",
        "    Transforms the data into SVD format\n",
        "    \"\"\"\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    data = Dataset.load_from_df(user_artists[['userID', 'artistID', 'normalized_weight']], reader)\n",
        "    print(\"Data loaded into Surprise format\")\n",
        "\n",
        "    trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "    return trainset, testset\n",
        "\n",
        "trainset, testset = transform_data(user_artists)\n",
        "print(f\"Training set size: {trainset.n_ratings}\")\n",
        "print(f\"Test set size: {len(testset)}\")"
      ],
      "metadata": {
        "id": "3Ee0F4YD7vjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVD(\n",
        "    n_factors=150,\n",
        "    n_epochs=40,\n",
        "    reg_all=0.015,\n",
        "    lr_all=0.005\n",
        ")\n",
        "model.fit(trainset)\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "id": "wsxPOKhG8Flv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Evaluate the performance of the model using the test set"
      ],
      "metadata": {
        "id": "UqiAieK0_CPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "\n",
        "predictions = model.test(testset)\n",
        "\n",
        "rmse = accuracy.rmse(predictions)\n",
        "mae = accuracy.mae(predictions)"
      ],
      "metadata": {
        "id": "UvRrM3Lt_Hhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_error():\n",
        "    \"\"\"\n",
        "    Plot error distribution for dataset\n",
        "    \"\"\"\n",
        "    # Extract actual and predicted values from the predictions\n",
        "    actual = [pred.r_ui for pred in predictions]\n",
        "    predicted = [pred.est for pred in predictions]\n",
        "    errors = np.array(actual) - np.array(predicted)\n",
        "\n",
        "    # Plot error distribution\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.violinplot(x=errors, color='skyblue', density_norm='width', inner=None)\n",
        "    plt.axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
        "    plt.xlim(-0.75, 0.75)\n",
        "\n",
        "    plt.title('Error Distribution', fontsize=16)\n",
        "    plt.xlabel('Error', fontsize=14)\n",
        "    plt.ylabel('Density', fontsize=14)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_error()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cqOBxkgvSQoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ape():\n",
        "    \"\"\"\n",
        "    Plot absolute percent error\n",
        "    \"\"\"\n",
        "    actual = np.array([pred.r_ui for pred in predictions])\n",
        "    predicted = np.array([pred.est for pred in predictions])\n",
        "\n",
        "    # Calculate Absolute Percentage Error (APE)\n",
        "    ape = np.abs((actual - predicted) / actual) * 100\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.violinplot(x=ape, color='coral', inner=None)\n",
        "    plt.axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
        "    plt.xlim(0, 100)\n",
        "    plt.title('Absolute Percentage Error Distribution', fontsize=16)\n",
        "    plt.xlabel('Error (%)', fontsize=14)\n",
        "    plt.ylabel('Density', fontsize=14)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "\n",
        "plot_ape()"
      ],
      "metadata": {
        "id": "s80JuTDGQXdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def precision_recall_at_k(predictions, k, threshold):\n",
        "    \"\"\"\n",
        "    Calculate precision and recall (and F1 score)\n",
        "    \"\"\"\n",
        "    user_est_true = defaultdict(list)\n",
        "    for pred in predictions:\n",
        "        # (predicted, actual)\n",
        "        user_est_true[pred.uid].append((pred.est, pred.r_ui))\n",
        "\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        top_k = user_ratings[:k]\n",
        "\n",
        "        # Calculate the number of relevant items based on a rating threshold\n",
        "        n_relevant = sum(1 for (pred, actual) in top_k if actual >= threshold)\n",
        "        n_relevant_total = sum(1 for (pred, actual) in user_ratings if actual >= threshold)\n",
        "\n",
        "        precision = n_relevant / k if k > 0 else 0\n",
        "        recall = n_relevant / n_relevant_total if n_relevant_total > 0 else 0\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
        "\n",
        "    return avg_precision, avg_recall, avg_f1\n",
        "\n",
        "# Print precision, recall, F1 score for varying k and threshold\n",
        "for k in [5, 10, 20]:\n",
        "    for thresh in [0.5, 1.0, 2.0]:\n",
        "        precision, recall, f1 = precision_recall_at_k(predictions, k, thresh)\n",
        "        print(f\"k={k}, threshold={thresh} -> Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Pm7zUI6DY2Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(user_id, n_recommendations=5, threshold=0.75):\n",
        "    \"\"\"\n",
        "    Generate top n artist recommendations for a given user\n",
        "    \"\"\"\n",
        "    all_artists = user_artists['artistID'].unique()\n",
        "    predictions = [model.predict(user_id, artist_id) for artist_id in all_artists]\n",
        "    filtered_predictions = [pred for pred in predictions if pred.est >= threshold]\n",
        "    filtered_predictions.sort(key=lambda k: k.est, reverse=True)\n",
        "    top_artists = [pred.iid for pred in filtered_predictions[:n_recommendations]]\n",
        "    recommended_artists = artists[artists['id'].isin(top_artists)]['name'].tolist()\n",
        "\n",
        "    return recommended_artists\n",
        "\n",
        "user_id = 2\n",
        "recommendations = get_recommendations(user_id)\n",
        "print(f\"Top recommendations for user {user_id}: {recommendations}\")"
      ],
      "metadata": {
        "id": "Atmbl8cA_b5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}