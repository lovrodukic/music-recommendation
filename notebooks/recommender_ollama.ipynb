{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovrodukic/music-recommendation/blob/main/notebooks/recommender_ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuUr2BEb6jTV"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o_-c3426g0t"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas faiss-gpu requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAKRo5kt6nsL"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oyqURyJ8Zgp"
      },
      "outputs": [],
      "source": [
        "!nohup ollama serve &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MixZuk8E9Wn4"
      },
      "outputs": [],
      "source": [
        "!ollama pull llama2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY7zyaJC6pXR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('tracks_features.csv').drop(\n",
        "    columns=['id', 'album_id', 'artist_ids', 'track_number',\n",
        "                'disc_number', 'duration_ms', 'time_signature', 'year',\n",
        "                'release_date'],\n",
        "    errors='ignore'\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_ppaopK61Y4"
      },
      "outputs": [],
      "source": [
        "def create_textual_representation(row):\n",
        "    return (\n",
        "        f\"Track: {row['name']},\\n\"\n",
        "        f\"Album: {row['album']},\\n\"\n",
        "        f\"Artists: {row['artists'][1:-1]},\\n\"\n",
        "        f\"Explicit: {row['explicit']}\"\n",
        "    )\n",
        "\n",
        "df['textual_representation'] = df.apply(\n",
        "    create_textual_representation,\n",
        "    axis=1\n",
        ")\n",
        "print(df['textual_representation'].values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DM4DVk162fY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "def generate_embedding(representation):\n",
        "    \"\"\"\n",
        "    Generate textual embedding based on selected model\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            'http://localhost:11434/api/embeddings',\n",
        "            json={'model': 'llama2', 'prompt': representation}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        return np.array(response.json()['embedding'], dtype='float32')\n",
        "    except requests.RequestException as e:\n",
        "        raise ValueError(f\"Error generating Ollama embedding: {e}\")\n",
        "\n",
        "def build_index(index_name, batch_size=1000):\n",
        "    \"\"\"\n",
        "    Build the FAISS index using using song textual representations\n",
        "    \"\"\"\n",
        "    num_rows = len(df)\n",
        "    print(f\"Total songs: {num_rows}\")\n",
        "\n",
        "    for start_idx in range(0, len(df), batch_size):\n",
        "        end_idx = min(start_idx + batch_size, num_rows)\n",
        "        print(f\"Processing songs {start_idx} to {end_idx}...\")\n",
        "\n",
        "        # Prepare batch embeddings\n",
        "        batch_embeddings = np.zeros(\n",
        "            (end_idx - start_idx, 4096 + 11),\n",
        "            dtype='float32'\n",
        "        )\n",
        "\n",
        "        for i, row in enumerate(\n",
        "            df.iloc[start_idx:end_idx].iterrows()\n",
        "        ):\n",
        "            song_idx, song_row = row\n",
        "\n",
        "            # Generate textual embedding\n",
        "            try:\n",
        "                textual_embedding = generate_embedding(\n",
        "                    song_row['textual_representation']\n",
        "                )\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping song {song_idx} due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Extract numerical features\n",
        "            numerical_features = song_row[\n",
        "                ['danceability', 'energy', 'key', 'loudness', 'mode',\n",
        "                    'speechiness', 'acousticness', 'instrumentalness',\n",
        "                    'liveness', 'valence', 'tempo']\n",
        "            ].values.astype('float32')\n",
        "\n",
        "            # Combine textual and numerical embeddings\n",
        "            batch_embeddings[i] = np.concatenate(\n",
        "                [textual_embedding, numerical_features]\n",
        "            )\n",
        "\n",
        "        # Add batch embeddings to FAISS index\n",
        "        faiss_index.add(batch_embeddings)\n",
        "\n",
        "    faiss.write_index(self.faiss_index, f\"models/{index_name}\")\n",
        "    print(f\"Saved FAISS index to models/{index_name}\")\n",
        "\n",
        "build_index('index', batch_size=1000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNTI3m7kKEFjdbGH52Yn0Y6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}